{"cells":[{"cell_type":"markdown","metadata":{"id":"gcTwzhX8fBqs"},"source":["Code based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n","\n","In this exercise, we are going to implement a [ResNet-like](https://arxiv.org/pdf/1512.03385.pdf) architecture for the image classification task.\n","The model is trained on the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset.\n","\n","Tasks:\n","\n","    1. Implement residual connections in the missing places in the code.\n","\n","    2. Check that the given implementation reaches 97% test accuracy after a few epochs.\n","\n","    3. Check that when extending the residual blocks to 20 (having 40+ layers total), the model still trains well, i.e., achieves 97+% accuracy after three epochs."]},{"cell_type":"markdown","metadata":{"id":"8d386b26"},"source":["Note: in this lab scenario we are using mypy for typing. You can disable easily by not running the cell below.\n","Typing in python is not mandatory, but if the types are natural, it can lead to less debugging, especially\n","that types can be checked statically without running the code (typically done even within IDE)."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"ba2eeffc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732721392461,"user_tz":-60,"elapsed":23044,"user":{"displayName":"Jakub Giezgała","userId":"00384255565915061433"}},"outputId":"4dca3af0-b2d5-46f8-a4af-ec9f6d6705b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.9/819.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for nb-mypy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.29.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]},{"output_type":"stream","name":"stderr","text":["Version 1.0.5\n","INFO:nb-mypy:Version 1.0.5\n"]}],"source":["!pip install nb-mypy -qqq\n","%load_ext nb_mypy"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"IYAsziKffBFV","executionInfo":{"status":"ok","timestamp":1732721467091,"user_tz":-60,"elapsed":74636,"user":{"displayName":"Jakub Giezgała","userId":"00384255565915061433"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","# There is no typing for torchvision yet.\n","from torchvision import datasets, transforms # type: ignore\n","from torch.utils.data import DataLoader\n","from typing_extensions import TypedDict\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"FeObV3DtNQAL","executionInfo":{"status":"ok","timestamp":1732723112695,"user_tz":-60,"elapsed":38799,"user":{"displayName":"Jakub Giezgała","userId":"00384255565915061433"}}},"outputs":[],"source":["class ResidualConnection(nn.Module):\n","    def __init__(self, in_channels: int, out_channels: int) -> None:\n","        super().__init__()\n","        self.conv_block_1 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=in_channels,\n","                out_channels=out_channels,\n","                kernel_size=3,\n","                padding=1,\n","            ),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","        )\n","        self.conv_block_2 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=out_channels,\n","                out_channels=out_channels,\n","                kernel_size=3,\n","                padding=1,\n","            ),\n","            nn.BatchNorm2d(out_channels),\n","        )\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        # TODO: implement forward function\n","        residual = x\n","        x = self.conv_block_1(x)\n","        return self.conv_block_2(x) + residual"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"qgu924wGNQAM","executionInfo":{"status":"ok","timestamp":1732723149297,"user_tz":-60,"elapsed":36607,"user":{"displayName":"Jakub Giezgała","userId":"00384255565915061433"}}},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self) -> None:\n","        super(Net, self).__init__()\n","        self.rc = nn.Sequential(\n","            ResidualConnection(1, 16),\n","            # TODO: verify that after increasing 3 to 19 still trains\n","            *(ResidualConnection(16, 16) for _ in range(3)),\n","        )\n","        self.fc = nn.Linear(\n","            28 * 28 * 16, 10\n","        )  # 28 * 28 * 16 is the size of flattened output of the last ResidualConnection\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = self.rc(x)\n","        x = nn.Flatten(start_dim=1)(x)\n","        x = self.fc(x)\n","        output = nn.LogSoftmax(dim=1)(x)\n","        return output"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"DMtap4QCfBH8","executionInfo":{"status":"ok","timestamp":1732723221714,"user_tz":-60,"elapsed":72424,"user":{"displayName":"Jakub Giezgała","userId":"00384255565915061433"}}},"outputs":[],"source":["def train(model: nn.Module, device: torch.device, train_loader: DataLoader,\n","          optimizer: optim.Optimizer, epoch: int, log_interval: int) -> None:\n","    model.train()\n","    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch}\")\n","    for batch_idx, (data, target) in pbar:\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % log_interval == 0:\n","            pbar.set_postfix(loss=loss.item())\n","\n","\n","def test(model: nn.Module, device: torch.device, test_loader: DataLoader) -> None:\n","    model.eval()\n","    test_loss = 0.\n","    correct = 0\n","    test_set_size = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            test_set_size += data.shape[0]\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(\n","                output, target, reduction=\"sum\"\n","            ).item()  # sum up batch loss\n","            pred = output.argmax(\n","                dim=1, keepdim=True\n","            )  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= test_set_size\n","\n","    print(\n","        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n","            test_loss,\n","            correct,\n","            test_set_size,\n","            100.0 * correct / test_set_size,\n","        )\n","    )"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"K5GlMs1-fBKP","executionInfo":{"status":"ok","timestamp":1732723262326,"user_tz":-60,"elapsed":40619,"user":{"displayName":"Jakub Giezgała","userId":"00384255565915061433"}}},"outputs":[],"source":["batch_size = 256\n","test_batch_size = 1000\n","epochs = 3\n","lr = 1e-2\n","seed = 1\n","log_interval = 10"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"WgfUP23AfBMd","executionInfo":{"status":"ok","timestamp":1732723302452,"user_tz":-60,"elapsed":40133,"user":{"displayName":"Jakub Giezgała","userId":"00384255565915061433"}}},"outputs":[],"source":["use_cuda = torch.cuda.is_available()\n","\n","torch.manual_seed(seed)\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","DataloaderArgs = TypedDict('DataloaderArgs', {'batch_size': int, 'shuffle': bool, 'num_workers': int, 'pin_memory': bool}, total=False)\n","\n","train_kwargs: DataloaderArgs = {\"batch_size\": batch_size}\n","test_kwargs: DataloaderArgs = {\"batch_size\": test_batch_size}\n","if use_cuda:\n","    cuda_kwargs: DataloaderArgs = {\"num_workers\": 1, \"pin_memory\": True, \"shuffle\": True}\n","    train_kwargs.update(cuda_kwargs)\n","    test_kwargs.update(cuda_kwargs)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"o0KPoUtsfBOs","executionInfo":{"status":"ok","timestamp":1732723340315,"user_tz":-60,"elapsed":37872,"user":{"displayName":"Jakub Giezgała","userId":"00384255565915061433"}}},"outputs":[],"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",")\n","dataset1 = datasets.MNIST(\"../data\", train=True, download=True, transform=transform)\n","dataset2 = datasets.MNIST(\"../data\", train=False, transform=transform)\n","train_loader = DataLoader(dataset1, **train_kwargs)\n","test_loader = DataLoader(dataset2, **test_kwargs)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezvIQbgsfBRT","outputId":"b310a2ae-671d-49b0-b9e5-2130f8c29a1e","executionInfo":{"status":"ok","timestamp":1732724111886,"user_tz":-60,"elapsed":771578,"user":{"displayName":"Jakub Giezgała","userId":"00384255565915061433"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|██████████| 235/235 [03:46<00:00,  1.04it/s, loss=0.00667]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.2086, Accuracy: 9697/10000 (97%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2: 100%|██████████| 235/235 [03:34<00:00,  1.10it/s, loss=0.00224]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.1882, Accuracy: 9708/10000 (97%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3: 100%|██████████| 235/235 [03:35<00:00,  1.09it/s, loss=1.47e-5]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.1613, Accuracy: 9708/10000 (97%)\n","\n"]}],"source":["model = Net().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","for epoch in range(1, epochs + 1):\n","    train(model, device, train_loader, optimizer, epoch, log_interval)\n","    test(model, device, test_loader)"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/mim-ml-teaching/public-dnn-2024-25/blob/master/docs/DNN-Lab-7-ResidualBlock-in-Pytorch-student-version.ipynb","timestamp":1732721342427}]},"kernelspec":{"display_name":"Python 3.9.13 ('.venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"6fa2fa4f4d9d3d9ca73eb3739cc0e85a72773041ed8c7376d5dc2c41e6946bf8"}}},"nbformat":4,"nbformat_minor":0}